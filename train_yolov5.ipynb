{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57009e4d-0207-411a-9385-3feff7341df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import random\n",
    "import shutil\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from psutil import virtual_memory\n",
    "from torch.cuda import is_available, device_count, get_device_name, get_arch_list\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(241)\n",
    "\n",
    "gpu_num = '5'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_num # Set to GPU 0 on Training\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33bac2-efeb-49ec-8416-cda72daf1dac",
   "metadata": {},
   "source": [
    "### Check Detected Device by Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b995da2-e27b-4b97-8d81-d426f71617bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Compute Capability\n",
      "['sm_50', 'sm_60', 'sm_70', 'sm_75', 'sm_80', 'sm_86', 'sm_90']\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA H100 80GB HBM3\n",
      "Total RAM size: 2015.36 GB\n",
      "CPU name: Intel(R) Xeon(R) Platinum 8480+\n",
      "Number of CPU threads: 112\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check PyTorch version and available CUDA architectures\n",
    "print('PyTorch Compute Capability')\n",
    "print(get_arch_list())\n",
    "\n",
    "# Check if CUDA is available\n",
    "if is_available():\n",
    "    # Get the number of available GPUs\n",
    "    num_gpus = device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    \n",
    "    # Print information about each GPU\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. GPU support is not enabled.\")\n",
    "\n",
    "# Get system RAM size\n",
    "ram_size = virtual_memory().total / (1024 ** 3)  # Convert bytes to gigabytes\n",
    "print(f\"Total RAM size: {ram_size:.2f} GB\")\n",
    "\n",
    "# Get CPU name\n",
    "cpu_name = None\n",
    "with open(\"/proc/cpuinfo\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if \"model name\" in line:\n",
    "            cpu_name = line.strip().split(\": \")[1]\n",
    "            break\n",
    "print(f\"CPU name: {cpu_name}\")\n",
    "\n",
    "# Get number of CPU threads\n",
    "num_cores = cpu_count() // 2\n",
    "print(f\"Number of CPU threads: {num_cores}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e16a04b-9c53-489b-b546-0da5429179ab",
   "metadata": {},
   "source": [
    "### Define Path and Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d44ef13-5d84-4333-b48b-a4a0638d5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"yolov5n-seg.yaml\" # Architecture Recepie\n",
    "data_name = \"temp\" # Dataset Name\n",
    "fold = 5 #CV Fold\n",
    "\n",
    "train_image_path = 'dataset/train/s2_image/' # Train image path\n",
    "train_label_path = 'dataset/train/mask/' # Train label path\n",
    "\n",
    "evaluation_image_path = 'dataset/evaluation/s2_image/' # Evaluation image path\n",
    "evaluation_label_path = 'dataset/evaluation/mask/' # Evaluation label path\n",
    "\n",
    "wd = os.getcwd() # Get the current directory path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac142d24-32ed-49bc-a01f-00131d77f15a",
   "metadata": {},
   "source": [
    "### Preprocess Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2b25ac-dce8-4ec6-a09c-825281402187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(path, remove_extension=False) :\n",
    "    '''\n",
    "    This function is to get all the file names in a folder.\n",
    "    remove_extension argument is for removing the file extension\n",
    "\n",
    "    remove_extension=False\n",
    "        [file_1.jpg, file_2.tiff, file_3.txt]\n",
    "    remove_extension=True\n",
    "        [file_1, file_2, file_3]\n",
    "\n",
    "    Filtering of .ipynb_checkpoints, .gitignore, and __pycache__\n",
    "    '''\n",
    "    \n",
    "    if remove_extension :\n",
    "        return sorted([i.split('.')[0] for i in os.listdir(path) if i[0] != '.' or i[0] != '_'])\n",
    "    else :\n",
    "        return sorted([i for i in os.listdir(path) if i[0] != '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a841d28-3d24-4209-b1f6-2f6d2c58f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path) :\n",
    "    '''\n",
    "    Read all the .tif images inside a folder and \n",
    "    return a python list that consist of numpy array of the image.\n",
    "    '''\n",
    "\n",
    "    # Get all the file names from the given path\n",
    "    file_names = get_file_names(path)\n",
    "\n",
    "    # Read all the images in the path and store it in a python list\n",
    "    images = []\n",
    "    for file_name in file_names :\n",
    "        file_path = os.path.join(path, file_name)\n",
    "        # Save as float32\n",
    "        image = tiff.imread(file_path).astype(np.float32)\n",
    "\n",
    "        images.append(image)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e1d2ae-ac25-49f3-b23b-2971ff3402c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_band(band, images) :\n",
    "    '''\n",
    "    Select the individual band of each image from a list of images\n",
    "    extracted_channels = [[channel_n of image_1], [channel_n of image_2], ...]\n",
    "\n",
    "    the extracted_channels is a python list consisting of 2D (h, w) numpy array\n",
    "    representing the single channel from each image.\n",
    "    '''\n",
    "\n",
    "    extracted_channel = []\n",
    "    for image in images :\n",
    "        # Select a single band from h, w, c format\n",
    "        extracted_channel.append(image[:, :, band])\n",
    "\n",
    "    return extracted_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ec1435-5adb-489d-978c-5d1f23d57299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_min_max(arr) :\n",
    "    '''\n",
    "    Normalized all the images inside the python list from the global minimum\n",
    "    and maximum.\n",
    "\n",
    "    The normalized image is multiplied by 255 so the range is [0, 255]\n",
    "    '''\n",
    "    # Min and max value used\n",
    "    min_val, max_val = 0, 10000\n",
    "    \n",
    "    normalized_img = []\n",
    "    for img in arr :\n",
    "        img[img > 10000] = 10000 # Clip value above 10000\n",
    "        \n",
    "        img = ( (img - min_val) / (max_val - min_val) ) * 255\n",
    "        normalized_img.append(img)\n",
    "\n",
    "    return normalized_img\n",
    "\n",
    "def norm_min_max_image(image, min_val=None, max_val=None) :\n",
    "    '''\n",
    "    Normalized single image and multiplied by 255\n",
    "    '''\n",
    "\n",
    "    # Get the min max value from the image if the min and max value is not given\n",
    "    if min_val == None and max_val == None :\n",
    "        min_val, max_val = np.min(image), np.max(image)\n",
    "        \n",
    "    image = ( (image - min_val) / (max_val - min_val) ) * 255\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbdc58ef-98a1-4491-9257-0b4f8cceb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formula(bandA, bandB) :\n",
    "    '''\n",
    "    Formula for finding ratio between two spectral bands\n",
    "    '''\n",
    "    new_band = []\n",
    "    for i in range(len(bandA)) :\n",
    "        a, b = bandA[i], bandB[i]\n",
    "        processed_band = (a-b) / ((a+b) + 1e-10)\n",
    "\n",
    "        # The ratio will have a range of [-1, 1]\n",
    "        processed_band = norm_min_max_image(processed_band, min_val=-1, max_val=1)\n",
    "        \n",
    "        new_band.append(processed_band)\n",
    "\n",
    "    return new_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ad19157-b0e0-4f7c-8280-cd77b3db9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_images(images, source_path, export_path) :\n",
    "    '''\n",
    "    Export the preprocessed image to .tif format\n",
    "\n",
    "    images : array of the stacked images (h, w, c)\n",
    "    source_path : the source image path to get the original file name\n",
    "    export_path : the path for the .tif image to be written\n",
    "    '''\n",
    "    # Get the original file names\n",
    "    file_names = get_file_names(source_path)\n",
    "\n",
    "    for image, file_name in zip(images, file_names) :\n",
    "        H, W, C = image.shape\n",
    "\n",
    "        # Resize the image to match the inputsize as close as possible\n",
    "        image = cv2.resize(image, (W * 10, H * 10), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        file_path = os.path.join(export_path, file_name)\n",
    "        tiff.imwrite(file_path, image) # Write the preprocessed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304586a1-f315-4b79-b2c0-df7f79fd96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_labels(label_source_path, label_export_path) :\n",
    "    '''\n",
    "    Convert the binary .tif mask to YOLO label .txt format\n",
    "\n",
    "    label_source_path : the folder path containing .tif binary mask\n",
    "    label_export_path : the folder for the .txt labels to be written\n",
    "    '''\n",
    "    \n",
    "    file_names = get_file_names(label_source_path)\n",
    "\n",
    "    for file_name in file_names :\n",
    "        file_path = os.path.join(label_source_path, file_name)\n",
    "        mask = tiff.imread(file_path)\n",
    "        H, W = mask.shape\n",
    "\n",
    "        # Resize the image 10 times with linear interpolation to match the image size\n",
    "        # !!! Please match the size and interpolation of the image for optimal mask representation\n",
    "        mask = cv2.resize(mask, (W * 10, H * 10), interpolation=cv2.INTER_LINEAR)\n",
    "        _, mask = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY) # Convert to 0 and 255 mask\n",
    "\n",
    "        H, W = mask.shape\n",
    "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "        # Convert the contours to polygons\n",
    "        polygons = []\n",
    "        for cnt in contours:\n",
    "            if cv2.contourArea(cnt) > 0:\n",
    "                polygon = []\n",
    "                for point in cnt:\n",
    "                    x, y = point[0]\n",
    "                    polygon.append(x / W)\n",
    "                    polygon.append(y / H)\n",
    "                polygons.append(polygon)\n",
    "    \n",
    "        # Write the polygons\n",
    "        file_name = file_name.replace('mask', 's2_image')[:-4]+'.txt'\n",
    "        with open(os.path.join(label_export_path, file_name), 'w') as f:\n",
    "            for polygon in polygons:\n",
    "                for p_, p in enumerate(polygon):\n",
    "                    if p_ == len(polygon) - 1:\n",
    "                        f.write('{}\\n'.format(p))\n",
    "                    elif p_ == 0:\n",
    "                        f.write('0 {} '.format(p))\n",
    "                    else:\n",
    "                        f.write('{} '.format(p))\n",
    "    \n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c5bb8d5-a26c-4cd5-859f-47284645d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_directory(data_name) :\n",
    "    '''\n",
    "    Create a folder and subfolder structure for the preprocessed images and\n",
    "    converted labels\n",
    "\n",
    "    |-train_yolov5.ipynb\n",
    "    |\n",
    "    |\n",
    "    |-preprocessed_data\n",
    "    |    |-{data_name}\n",
    "    |    |    |-train\n",
    "    |    |    |    |-images\n",
    "    |    |    |    |    |-preprocessed_image.tif\n",
    "    |    |    |    |    |- ...\n",
    "    |    |    |    |    \n",
    "    |    |    |    |-labels\n",
    "    |    |    |         |-preprocessed_image.txt\n",
    "    |    |    |         |- ...\n",
    "    |    |    |-evaluation\n",
    "    |    |    |    |-images\n",
    "    |    |    |    |    |-preprocessed_image.tif\n",
    "    |    |    |    |    |- ...\n",
    "    |    |    |    |    \n",
    "    |    |    |    |-labels\n",
    "    |    |    |         |-preprocessed_image.txt\n",
    "    |    |    |         |- ...\n",
    "    |    |\n",
    "    |    |-{other_data_name}\n",
    "    |    |    | ...\n",
    "    |    \n",
    "    '''\n",
    "\n",
    "    # Define the main directory\n",
    "    working_dir = os.getcwd()\n",
    "    container_dir = os.path.join(working_dir, 'preprocessed_data')\n",
    "    data_dir = os.path.join(container_dir, data_name)\n",
    "\n",
    "    # Directory for images and labels on each set\n",
    "    sub_dirs = [\n",
    "        'train/images',\n",
    "        'train/labels',\n",
    "        'evaluation/images',\n",
    "        'evaluation/labels'\n",
    "    ]\n",
    "\n",
    "    for sub_dir in sub_dirs :\n",
    "        os.makedirs(os.path.join(data_dir, sub_dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b4c5e68-ef5b-4e49-9929-363ac77cad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image_source_path, image_export_path) :\n",
    "    # Output the source path, export path, and the number of images\n",
    "    print('Source Path : ', image_source_path)\n",
    "    print('Export Path : ', image_export_path)\n",
    "    print('Images Count : ', len(get_file_names(image_source_path)))\n",
    "    \n",
    "    # Array of train data images\n",
    "    image_source = read_images(image_source_path)\n",
    "    \n",
    "    # Num of channels to be extracted from the original .tif file\n",
    "    ch_num = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "    channels = []\n",
    "    normalized_channels = []\n",
    "    \n",
    "    # Select the first 12 channels from the image source\n",
    "    for i in ch_num :\n",
    "        ch = select_band(i, image_source)\n",
    "        normalized_ch = norm_min_max(ch)\n",
    "        \n",
    "        channels.append(ch)\n",
    "        normalized_channels.append(normalized_ch)\n",
    "    \n",
    "    # Create a new channel from permutation of channels (2,3,4)\n",
    "    for i in range(1, 4) :\n",
    "        for j in range(1, 4) :\n",
    "            if i != j :\n",
    "                ch = formula(normalized_channels[i], normalized_channels[j])\n",
    "                normalized_channels.append(ch)\n",
    "    \n",
    "    # Create a new channel from permutation of channels (10,11)\n",
    "    for i in range(10, 12) :\n",
    "        for j in range(10, 12) :\n",
    "            if i != j :\n",
    "                ch = formula(normalized_channels[i], normalized_channels[j])\n",
    "                normalized_channels.append(ch)\n",
    "    \n",
    "    # Create the image to h, w, c format\n",
    "    images = [np.stack([normalized_channels[i][j] for i in range(len(normalized_channels))], axis=-1, dtype=np.float32) for j in range(len(normalized_channels[0]))]\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba03eada-9bac-4350-976e-7a8e9f5b9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folder structure based on the path\n",
    "make_data_directory(data_name)\n",
    "\n",
    "# Define the train source path and the export path from user defined path\n",
    "train_image_source_path = os.path.join(wd, train_image_path)\n",
    "train_image_export_path = os.path.join(wd, 'preprocessed_data', data_name, 'train', 'images')\n",
    "train_label_source_path = os.path.join(wd, train_label_path)\n",
    "train_label_export_path = os.path.join(wd, 'preprocessed_data', data_name, 'train', 'labels')\n",
    "\n",
    "# Define the evaluation source path and the export path from user defined path\n",
    "evaluation_image_source_path = os.path.join(wd, evaluation_image_path)\n",
    "evaluation_image_export_path = os.path.join(wd, 'preprocessed_data', data_name, 'evaluation', 'images')\n",
    "evaluation_label_source_path = os.path.join(wd, evaluation_label_path)\n",
    "evaluation_label_export_path = os.path.join(wd, 'preprocessed_data', data_name, 'evaluation', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2f74e21-dd35-4356-98ea-812bd7e6b52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Path :  /datadisk2/c241_ml02/workspace/dataset/train/s2_image/\n",
      "Export Path :  /datadisk2/c241_ml02/workspace/preprocessed_data/temp/train/images\n",
      "Images Count :  2066\n",
      "Exporting Train Data...\n",
      "Train Data Exported\n"
     ]
    }
   ],
   "source": [
    "# Preprocess train images\n",
    "train_images = preprocess_images(\n",
    "    train_image_source_path,\n",
    "    train_image_export_path,\n",
    ")\n",
    " \n",
    "print('Exporting Train Data...')\n",
    "# Export the preprocessed train images\n",
    "export_images(train_images, train_image_source_path, train_image_export_path)\n",
    "# Export the label to yolo format\n",
    "export_labels(train_label_source_path, train_label_export_path)\n",
    "\n",
    "print('Train Data Exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "391bfa3e-2427-4d57-8947-9602b42a7d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Path :  /datadisk2/c241_ml02/workspace/dataset/evaluation/s2_image/\n",
      "Export Path :  /datadisk2/c241_ml02/workspace/preprocessed_data/temp/evaluation/images\n",
      "Images Count :  2066\n",
      "Exporting Evaluation Data...\n",
      "Evaluation Data Exported\n"
     ]
    }
   ],
   "source": [
    "# Preprocess evaluation images\n",
    "evaluation_images = preprocess_images(\n",
    "    evaluation_image_source_path,\n",
    "    evaluation_image_export_path,\n",
    ")\n",
    "\n",
    "print('Exporting Evaluation Data...')\n",
    "# Export the preprocessed evaluation images\n",
    "export_images(evaluation_images, evaluation_image_source_path, evaluation_image_export_path)\n",
    "# Write the dummy label\n",
    "export_labels(evaluation_label_source_path, evaluation_label_export_path)\n",
    "\n",
    "print('Evaluation Data Exported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac126ef3-e164-4b6a-bfce-127a36af3eed",
   "metadata": {},
   "source": [
    "### Create 5 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d416b86-8c14-42c3-979e-cb7874771802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fold(file_names, fold) :\n",
    "    # Shuffle the images\n",
    "    random.shuffle(file_names)\n",
    "\n",
    "    # Define each fold size\n",
    "    fold_sizes = [len(file_names) // fold for i in range(fold)]\n",
    "\n",
    "    # Distribute the remaining divider\n",
    "    for i in range(len(file_names) - sum(fold_sizes)) :\n",
    "        fold_sizes[-1] += 1\n",
    "\n",
    "    # Assign each images to the fold\n",
    "    fold_data = []\n",
    "    for i in range(len(fold_sizes)) :\n",
    "        data = file_names[sum(fold_sizes[:i]): sum(fold_sizes[:i+1])]\n",
    "        fold_data.append(data)\n",
    "\n",
    "    return fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c1e03de-6e25-418b-bf87-3825621b1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_directory(data_name, n_fold) :\n",
    "    '''\n",
    "    Create a folder and subfolder structure for\n",
    "    the each fold of preprocessed image\n",
    "\n",
    "    |-train_yolov5.ipynb\n",
    "    |\n",
    "    |\n",
    "    |-train_data\n",
    "    |    |-{data_name}\n",
    "    |    |    |-configs\n",
    "    \n",
    "    |    |    |    |-evaluation_config.yaml\n",
    "    |    |    |    |-fold_1.yaml\n",
    "    |    |    |    |-...\n",
    "    |    |    |    \n",
    "    |    |    |-evaluation\n",
    "    |    |    |    |-images\n",
    "    |    |    |    |-labels\n",
    "    |    |    |\n",
    "    |    |    |-fold_1\n",
    "    |    |    |    |-train\n",
    "    |    |    |    |    |-images\n",
    "    |    |    |    |    |-labels\n",
    "    |    |    |    |\n",
    "    |    |    |    |-val\n",
    "    |    |    |         |-images\n",
    "    |    |    |         |-labels\n",
    "    |    |    |    \n",
    "    |    |    |-fold_n\n",
    "    |    |    |    |-...\n",
    "    |    |    \n",
    "    |    |-{other_data_name}\n",
    "    |    |    | ...\n",
    "    |    \n",
    "    '''\n",
    "\n",
    "    # Define the path for each foler\n",
    "    working_dir = os.getcwd()\n",
    "    container_path = os.path.join(working_dir, 'train_data')\n",
    "    data_path = os.path.join(container_path, data_name)\n",
    "    config_path = os.path.join(data_path, 'configs')\n",
    "    evaluation_path = os.path.join(data_path, 'evaluation')\n",
    "\n",
    "    evaluation_images_path = os.path.join(evaluation_path, 'images')\n",
    "    evaluation_labels_path = os.path.join(evaluation_path, 'labels')\n",
    "    \n",
    "\n",
    "    # Create the folders\n",
    "    os.makedirs(container_path, exist_ok=True)\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    os.makedirs(config_path, exist_ok=True)\n",
    "    os.makedirs(evaluation_path, exist_ok=True)\n",
    "\n",
    "    os.makedirs(evaluation_images_path, exist_ok=True)\n",
    "    os.makedirs(evaluation_labels_path, exist_ok=True)\n",
    "\n",
    "    # Make a subfolder for each folds\n",
    "    fold_paths = [f'fold_{(i+1)}' for i in range(n_fold)]\n",
    "    \n",
    "    for n in fold_paths :\n",
    "        fold_path = os.path.join(data_path, n)\n",
    "        train_path = os.path.join(fold_path, 'train')\n",
    "        val_path = os.path.join(fold_path, 'val')\n",
    "        \n",
    "        os.makedirs(fold_path, exist_ok=True)\n",
    "        os.makedirs(train_path, exist_ok=True)\n",
    "        os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "        for path in [train_path, val_path] :  \n",
    "            images_dir = os.path.join(path, 'images')\n",
    "            labels_dir = os.path.join(path, 'labels')\n",
    "\n",
    "            os.makedirs(images_dir, exist_ok=True)\n",
    "            os.makedirs(labels_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3dda96b-736f-4e7b-95b0-dc00bb55f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(data_name, source_path, destination_path, part) :\n",
    "    '''\n",
    "    Function for copy the preprocessed image and its labels\n",
    "    '''\n",
    "    for file_name in data_name :\n",
    "        image_file_name = file_name + '.tif'\n",
    "        label_file_name = file_name + '.txt'\n",
    "\n",
    "        # Path for images\n",
    "        image_source_path = os.path.join(source_path, 'images', image_file_name)\n",
    "        image_destination_path = os.path.join(destination_path, part, 'images', image_file_name)\n",
    "\n",
    "        # Path for labels\n",
    "        label_source_path = os.path.join(source_path, 'labels', label_file_name)\n",
    "        label_destination_path = os.path.join(destination_path, part, 'labels', label_file_name)\n",
    "\n",
    "        shutil.copy(image_source_path, image_destination_path) # Copy the image\n",
    "        shutil.copy(label_source_path, label_destination_path) # Copy the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2327f64c-52b7-454f-a17c-2b5024cb6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fold(data_name, fold_data, source_path, destination_path) :\n",
    "    '''\n",
    "    Make a fold with 1 fold as validation data and \n",
    "    the rest as train data.\n",
    "    '''\n",
    "    \n",
    "    for i in range(len(fold_data)) :\n",
    "        # Path for fold_n\n",
    "        fold_destination_path = os.path.join(destination_path, f'fold_{(i+1)}')\n",
    "\n",
    "        # Find the fold for the validation data\n",
    "        train_data = []\n",
    "        for fold in fold_data :\n",
    "            if fold_data[i] == fold :\n",
    "                copy_data(fold_data[i], source_path, fold_destination_path, 'val')\n",
    "            else :\n",
    "                # Add the fold data to train data\n",
    "                train_data += fold\n",
    "\n",
    "        # Copy the rest fold to the train path\n",
    "        copy_data(train_data, source_path, fold_destination_path, 'train')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebe513e1-69d1-4fea-a959-dca2c9dea8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_configs(fold, data_path, config_path) :    \n",
    "    '''\n",
    "    Write the config for the train and validation data for each fold\n",
    "    '''\n",
    "    for i in range(fold) :\n",
    "        \n",
    "        fold_path = os.path.join(data_path, f'fold_{(i+1)}') # The main fold folder\n",
    "\n",
    "        # Write the config as yaml\n",
    "        with open(os.path.join(config_path, f'fold_{(i+1)}.yaml'), 'w') as yaml :\n",
    "            config = f\"\"\"path: {fold_path}\n",
    "train: train\n",
    "val: val\n",
    "\n",
    "nc: 1\n",
    "names: ['solarpanel']\"\"\"\n",
    "\n",
    "            yaml.write(config)\n",
    "\n",
    "def write_evaluation_config(data_path, config_path) :\n",
    "    '''\n",
    "    Write the config of the evaluation data with the train and val data is\n",
    "    theh evaluation data itself\n",
    "    '''\n",
    "    config_path = os.path.join(config_path, 'evaluation.yaml')\n",
    "\n",
    "    with open(config_path, 'w') as yaml :\n",
    "        config = f\"\"\"path: {data_path}\n",
    "train: evaluation\n",
    "val: evaluation\n",
    "\n",
    "nc: 1\n",
    "names: ['solarpanel']\"\"\"\n",
    "\n",
    "        yaml.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3b20db0-5182-488b-a248-a42d83f11306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image_count(destination_path, fold) :\n",
    "    '''\n",
    "    Function to check the file number of each fold on the train and validation\n",
    "    '''\n",
    "\n",
    "    paths = [f'fold_{(i)}' for i in range(1, fold+1)]\n",
    "    for path in paths :\n",
    "        fold_path = os.path.join(destination_path, path)\n",
    "        train_image_path = os.path.join(fold_path, 'train', 'images')\n",
    "        train_label_path = os.path.join(fold_path, 'train', 'labels')\n",
    "        val_image_path = os.path.join(fold_path, 'val', 'images')\n",
    "        val_label_path = os.path.join(fold_path, 'val', 'labels')\n",
    "        \n",
    "        print(f'=== {path} ===')\n",
    "        print('Train Images:', len(os.listdir(train_image_path)))\n",
    "        print('Train Labels :', len(os.listdir(train_label_path)))\n",
    "        print('Val Images :', len(os.listdir(val_image_path)))\n",
    "        print('Val Labels :', len(os.listdir(val_label_path)))\n",
    "\n",
    "    fold_path = os.path.join(destination_path, 'evaluation')\n",
    "    evaluation_image_path = os.path.join(fold_path, 'images')\n",
    "    evaluation_label_path = os.path.join(fold_path, 'labels')\n",
    "\n",
    "    print('=== evaluation ===')\n",
    "    print('Evaluation Images:', len(os.listdir(evaluation_image_path)))\n",
    "    print('Evaluation Labels:', len(os.listdir(evaluation_label_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b79b433-5632-41f7-91c9-140846e60b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for preprocessed data and train data\n",
    "working_dir = os.getcwd()\n",
    "source_path = os.path.join(working_dir, 'preprocessed_data', data_name)\n",
    "destination_path = os.path.join(working_dir, 'train_data', data_name)\n",
    "config_path = os.path.join(destination_path, 'configs')\n",
    "train_source_path = os.path.join(source_path, 'train')\n",
    "evaluation_source_path = os.path.join(source_path, 'evaluation')\n",
    "\n",
    "\n",
    "make_train_directory(data_name, fold) # Create the folders\n",
    "\n",
    "# Get the file names\n",
    "file_names = get_file_names(os.path.join(source_path, 'train', 'images'), remove_extension=True)\n",
    "# Create the fold data based on the file names\n",
    "fold_data = create_fold(file_names, fold)\n",
    "# Create the fold and copy the data\n",
    "make_fold(data_name, fold_data, train_source_path, destination_path)\n",
    "# Write config for each fold\n",
    "write_configs(fold, destination_path, config_path)\n",
    "\n",
    "# Copy preprocessed evaluation data\n",
    "evaluation_name = get_file_names(os.path.join(evaluation_source_path, 'images'), remove_extension=True)\n",
    "copy_data(evaluation_name, evaluation_source_path, destination_path, 'evaluation')\n",
    "# Write config for evaluation\n",
    "write_evaluation_config(destination_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "815c5106-7b99-43f3-b50e-a278d797498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Image Count per Fold ===\n",
      "\n",
      "=== fold_1 ===\n",
      "Train Images: 1653\n",
      "Train Labels : 1653\n",
      "Val Images : 413\n",
      "Val Labels : 413\n",
      "=== fold_2 ===\n",
      "Train Images: 1653\n",
      "Train Labels : 1653\n",
      "Val Images : 413\n",
      "Val Labels : 413\n",
      "=== fold_3 ===\n",
      "Train Images: 1653\n",
      "Train Labels : 1653\n",
      "Val Images : 413\n",
      "Val Labels : 413\n",
      "=== fold_4 ===\n",
      "Train Images: 1653\n",
      "Train Labels : 1653\n",
      "Val Images : 413\n",
      "Val Labels : 413\n",
      "=== fold_5 ===\n",
      "Train Images: 1652\n",
      "Train Labels : 1652\n",
      "Val Images : 414\n",
      "Val Labels : 414\n",
      "=== evaluation ===\n",
      "Evaluation Images: 2066\n",
      "Evaluation Labels: 2066\n"
     ]
    }
   ],
   "source": [
    "# Check the file numbers\n",
    "print('\\n=== Image Count per Fold ===\\n')\n",
    "check_image_count(destination_path, fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166bd01d-7d6a-47c1-9f33-7637f256ed0f",
   "metadata": {},
   "source": [
    "### Train YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a26b7ab3-9507-415e-ba50-0c431f5405e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for the model size, defined in the begining of the code\n",
    "model_config_path = os.path.join(wd, 'yolov5', 'models', 'segment', model)\n",
    "# Config for the train data (fold_1 of the data name is the default)\n",
    "data_path = os.path.join(wd, 'train_data', data_name, 'configs', 'fold_1.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "16f87421-2f80-4309-a418-f24d781125ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1msegment/train: \u001b[0mweights=yolov5/yolov5s-seg.pt, cfg=/datadisk2/c241_ml02/workspace/yolov5/models/segment/yolov5n-seg.yaml, data=/datadisk2/c241_ml02/workspace/train_data/temp/configs/fold_1.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=128, imgsz=256, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=5, multi_scale=False, single_cls=False, optimizer=AdamW, sync_bn=False, workers=8, project=yolov5/runs/train-seg, name=temp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=300, freeze=[0], save_period=-1, seed=0, local_rank=-1, mask_ratio=4, no_overlap=True\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 18 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "YOLOv5 üöÄ v7.0-313-g712de55a Python-3.12.3 torch-2.3.1+cu121 CUDA:5 (NVIDIA H100 80GB HBM3, 81117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.0005, lrf=0.0005, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.4, anchor_t=4.0, fl_gamma=0.0, hsv_h=0, hsv_s=0, hsv_v=0, degrees=0, translate=0.1, scale=0.5, shear=0, perspective=0.0, flipud=0.5, fliplr=0.5, mosaic=0.2, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train-seg', view at http://localhost:6006/\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1     11552  models.common.Conv                      [20, 16, 6, 2, 2]             \n",
      "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
      "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
      "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
      "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
      "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
      " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
      " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
      " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 24      [17, 20, 23]  1    127510  models.yolo.Segment                     [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], 32, 64, [64, 128, 256]]\n",
      "YOLOv5n-seg summary: 225 layers, 1894454 parameters, 1894454 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 64/367 items from yolov5/yolov5s-seg.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks failed ‚ùå, disabling Automatic Mixed Precision. See https://github.com/ultralytics/yolov5/issues/7908\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0005) with parameter groups 60 weight(decay=0.0), 63 weight(decay=0.001), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /datadisk2/c241_ml02/workspace/train_data/temp/fold_1/train/labe\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /datadisk2/c241_ml02/workspace/train_data/temp/fold_1/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /datadisk2/c241_ml02/workspace/train_data/temp/fold_1/val/labels..\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /datadisk2/c241_ml02/workspace/train_data/temp/fold_1/val/labels.cache\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.41 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to yolov5/runs/train-seg/temp/labels.jpg... \n",
      "Image sizes 256 train, 256 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1myolov5/runs/train-seg/temp\u001b[0m\n",
      "Starting training for 10 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/9      8.38G     0.1047    0.07943    0.01825          0        359   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/9      12.1G     0.1022    0.07097    0.01916          0        404   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371    0.00229      0.207    0.00183   0.000488   0.000484     0.0438   0.000253    4.7e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/9      12.1G    0.09808    0.06499    0.01992          0        381   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/9      12.1G    0.09439    0.06106    0.02015          0        392   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/9      12.1G     0.0905    0.05893    0.02019          0        359   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        5/9      12.1G    0.08868    0.05757    0.02014          0        475   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371          0          0          0          0          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        6/9      12.1G    0.08622    0.05611    0.01989          0        405   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371    0.00322      0.291    0.00464    0.00101   0.000605     0.0547   0.000447   9.38e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        7/9      12.1G    0.08363    0.05527    0.01946          0        422   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371    0.00342      0.301    0.00796    0.00174    0.00395      0.273      0.008    0.00157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        8/9      12.1G    0.08331    0.05623    0.01917          0        381   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371      0.115      0.107     0.0307    0.00805      0.119     0.0999     0.0325    0.00899\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   obj_loss   cls_loss  Instances       Size\n",
      "        9/9      12.1G    0.08229    0.05507    0.01923          0        383   \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371       0.16       0.12     0.0538     0.0133      0.172       0.12     0.0532     0.0159\n",
      "\n",
      "10 epochs completed in 0.032 hours.\n",
      "Optimizer stripped from yolov5/runs/train-seg/temp/weights/last.pt, 4.0MB\n",
      "Optimizer stripped from yolov5/runs/train-seg/temp/weights/best.pt, 4.0MB\n",
      "\n",
      "Validating yolov5/runs/train-seg/temp/weights/best.pt...\n",
      "Fusing layers... \n",
      "YOLOv5n-seg summary: 165 layers, 1889542 parameters, 0 gradients, 8.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1371      0.158      0.118     0.0532     0.0134      0.175       0.12     0.0538     0.0161\n",
      "Results saved to \u001b[1myolov5/runs/train-seg/temp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train the yolov5\n",
    "!python yolov5/segment/train.py \\\n",
    "    --img 256 \\\n",
    "    --batch 128 \\\n",
    "    --epochs 10 \\\n",
    "    --data {data_path} \\\n",
    "    --cfg {model_config_path} \\\n",
    "    --device {gpu_num} \\\n",
    "    --no-overlap \\\n",
    "    --optimizer AdamW \\\n",
    "    --patience 300 \\\n",
    "    --name {data_name}\n",
    "\n",
    "\n",
    "# Weight of the yolov5 will be saved at\n",
    "# yolov5/runs/train-seg/{data_name}/weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ddc74-0060-4ad1-bd20-4493a8ecfb5e",
   "metadata": {},
   "source": [
    "### Evaluation Mask Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "924d0974-1a1b-4f94-be4b-525452b2de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_evaluation_folder(wd, data_name) :\n",
    "    '''\n",
    "    Create a folder for storing the binary mask of the evaluation set\n",
    "\n",
    "    |-train_yolov5.ipynb\n",
    "    |\n",
    "    |-masks\n",
    "         |-{data_name}\n",
    "              |-evaluation_mask_0.tif\n",
    "              |-...\n",
    "    '''\n",
    "    mask_folder = os.path.join(wd, 'masks', data_name)\n",
    "    os.makedirs(mask_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be9a05af-d1b7-4ed6-a9b8-6e1d1edc6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_validation_path(wd, data_name) :\n",
    "    '''\n",
    "    Delete the internal evaluation data inside the val-seg on the run folder\n",
    "    of yolov5.\n",
    "    '''\n",
    "    evaluation_result_path = os.path.join(wd, 'yolov5', 'runs', 'val-seg', data_name)\n",
    "    shutil.rmtree(evaluation_result_path) # Delete the whole folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9472061a-3659-4f94-9cec-47149fb0a3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/datadisk2/c241_ml02/workspace/yolov5/segment/evaluate.py\", line 576, in <module>\n",
      "    opt = parse_opt()\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/datadisk2/c241_ml02/workspace/yolov5/segment/evaluate.py\", line 532, in parse_opt\n",
      "    opt.data = check_yaml(opt.data)  # check YAML\n",
      "               ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/datadisk2/c241_ml02/workspace/yolov5/utils/general.py\", line 476, in check_yaml\n",
      "    return check_file(file, suffix)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/datadisk2/c241_ml02/workspace/yolov5/utils/general.py\", line 504, in check_file\n",
      "    assert len(files), f\"File not found: {file}\"  # assert file was found\n",
      "           ^^^^^^^^^^\n",
      "AssertionError: File not found: /datadisk2/c241_ml02/workspace/train_data/restructured_l/configs/evaluation.yaml\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datadisk2/c241_ml02/workspace/yolov5/runs/val-seg/restructured_l'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython \u001b[39m\u001b[38;5;132;01m{evaluate_path}\u001b[39;00m\u001b[38;5;124m      --weights \u001b[39m\u001b[38;5;132;01m{model_path}\u001b[39;00m\u001b[38;5;124m      --data \u001b[39m\u001b[38;5;132;01m{data_path}\u001b[39;00m\u001b[38;5;124m      --conf-thres \u001b[39m\u001b[38;5;132;01m{conf}\u001b[39;00m\u001b[38;5;124m      --imgsz 256      --name \u001b[39m\u001b[38;5;132;01m{data_name}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Delete the internal evaluation data\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[43mdelete_validation_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m, in \u001b[0;36mdelete_validation_path\u001b[0;34m(wd, data_name)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mDelete the internal evaluation data inside the val-seg on the run folder\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mof yolov5.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      6\u001b[0m evaluation_result_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(wd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov5\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mruns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval-seg\u001b[39m\u001b[38;5;124m'\u001b[39m, data_name)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmtree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluation_result_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/datadisk2/c241_ml02/anaconda3/envs/yolov5_sensevis/lib/python3.12/shutil.py:775\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[0m\n\u001b[1;32m    773\u001b[0m     orig_st \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlstat(path, dir_fd\u001b[38;5;241m=\u001b[39mdir_fd)\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 775\u001b[0m     \u001b[43monexc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/datadisk2/c241_ml02/anaconda3/envs/yolov5_sensevis/lib/python3.12/shutil.py:773\u001b[0m, in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;66;03m# Note: To guard against symlink races, we use the standard\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;66;03m# lstat()/open()/fstat() trick.\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 773\u001b[0m     orig_st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdir_fd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdir_fd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    775\u001b[0m     onexc(os\u001b[38;5;241m.\u001b[39mlstat, path, err)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datadisk2/c241_ml02/workspace/yolov5/runs/val-seg/restructured_l'"
     ]
    }
   ],
   "source": [
    "# Define the paths\n",
    "evaluate_path = os.path.join(wd, 'yolov5', 'segment', 'evaluate.py') # Evaluation to print the mask\n",
    "model_path = os.path.join(wd, 'yolov5', 'runs', 'train-seg', data_name, 'weights', 'best.pt') # Model to be evaluated\n",
    "data_path = os.path.join(wd, 'train_data' , data_name, 'configs', 'evaluation.yaml') # Config to the evaluation data\n",
    "\n",
    "# Create the folder to store the mask\n",
    "create_evaluation_folder(wd, data_name)\n",
    "\n",
    "# Evaluate\n",
    "!python {evaluate_path} \\\n",
    "    --weights {model_path} \\\n",
    "    --data {data_path} \\\n",
    "    --conf-thres {conf} \\\n",
    "    --imgsz 256 \\\n",
    "    --name {data_name}\n",
    "\n",
    "# Delete the internal evaluation data\n",
    "delete_validation_path(wd, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7e9bc9-69fc-4629-bfea-a76697ed6347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for the dummy masks and written masks\n",
    "mask_folder = os.path.join(wd, 'masks', data_name)\n",
    "extracted_masks = get_file_names(mask_folder)\n",
    "evaluation_file_names = get_file_names(evaluation_label_path)\n",
    "\n",
    "# Loop for write empty mask\n",
    "for file_name in evaluation_file_names :\n",
    "    if file_name not in extracted_masks :\n",
    "        h, w = tiff.imread(os.path.join(evaluation_label_path, file_name)).shape\n",
    "        empty_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "        output_mask_path = os.path.join(mask_folder, file_name)\n",
    "        tiff.imwrite(output_mask_path, empty_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d9af2-53b0-4a64-b8c7-e57c951f9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r masks_l_{conf}.zip masks/restructured_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
