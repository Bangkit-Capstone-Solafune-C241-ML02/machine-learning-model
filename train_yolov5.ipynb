{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57009e4d-0207-411a-9385-3feff7341df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "random.seed(241)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Set to GPU 0 on Training\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d44ef13-5d84-4333-b48b-a4a0638d5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"yolov5m-seg.yaml\" # Architecture Recepie\n",
    "data_name = \"20ch_minmax\" # Dataset Name\n",
    "fold = 5 #CV Fold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac142d24-32ed-49bc-a01f-00131d77f15a",
   "metadata": {},
   "source": [
    "### Preprocess Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe2b25ac-dce8-4ec6-a09c-825281402187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_names(path, remove_extension=False) :\n",
    "    if remove_extension :\n",
    "        return sorted([i.split('.')[0] for i in os.listdir(path) if i[0] != '.'])\n",
    "    else :\n",
    "        return sorted([i for i in os.listdir(path) if i[0] != '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a841d28-3d24-4209-b1f6-2f6d2c58f386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(path) :\n",
    "    file_names = get_file_names(path)\n",
    "\n",
    "    images = []\n",
    "    for file_name in file_names :\n",
    "        file_path = os.path.join(path, file_name)\n",
    "        \n",
    "        image = tiff.imread(file_path)\n",
    "\n",
    "        images.append(np.array(image, dtype=np.float32))\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e1d2ae-ac25-49f3-b23b-2971ff3402c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_band(band, path, preprocess=None) :\n",
    "    images = read_images(path)\n",
    "\n",
    "    extracted_channel = []\n",
    "\n",
    "    for image in images :\n",
    "        extracted_channel.append(image[:, :, band])\n",
    "\n",
    "    if preprocess == 'min_max' :\n",
    "        min, max = find_min_max(extracted_channel)\n",
    "        extracted_channel = norm_min_max(extracted_channel, min, max)\n",
    "\n",
    "    return extracted_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e78fba-bc6a-4c71-8b34-a6c5b4b3ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bands(a, b):\n",
    "    result = []\n",
    "    \n",
    "    for img_a, img_b in zip(a, b):\n",
    "        result.append(img_a + img_b)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def subtract_bands(a, b) :\n",
    "    result = []\n",
    "    \n",
    "    for img_a, img_b in zip(a, b):\n",
    "        result.append(img_a - img_b)\n",
    "\n",
    "    return result\n",
    "\n",
    "def multiply_bands(a, const) :\n",
    "    result = []\n",
    "\n",
    "    for img in a :\n",
    "        result.append(img * const)\n",
    "\n",
    "    return result\n",
    "\n",
    "def divide_bands(a, const) :\n",
    "    result = []\n",
    "\n",
    "    for img in a :\n",
    "        result.append(img / const)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fb6c8e6-6399-42dc-9baa-7801a5f9e353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_max(arr) :\n",
    "    min_val = np.min(arr[0])\n",
    "    max_val = np.max(arr[0])\n",
    "\n",
    "    for img in arr:\n",
    "        min_val = np.minimum(min_val, np.min(img))\n",
    "        max_val = np.maximum(max_val, np.max(img))\n",
    "\n",
    "    return min_val, max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a0e1ed-d24a-481b-b17c-abfc0c353897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(arr, min=0, max=1, ch=None) :\n",
    "    rescaled_img = []\n",
    "\n",
    "    for img in arr :\n",
    "        min, max = np.nanmin(img), np.nanmax(img)\n",
    "        img = (img - min)/(max-min)\n",
    "        rescaled_img.append(img)\n",
    "\n",
    "    return rescaled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbdc58ef-98a1-4491-9257-0b4f8cceb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formula(bandA, bandB) :\n",
    "    new_band = []\n",
    "    for i in range(len(bandA)) :\n",
    "        a, b = bandA[i], bandB[i]\n",
    "        processed_band = (a-b) / ((a+b) + 1e-10)\n",
    "        \n",
    "        new_band.append(processed_band)\n",
    "\n",
    "    return new_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad19157-b0e0-4f7c-8280-cd77b3db9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_images(images, source_path, export_path) :\n",
    "    file_names = get_file_names(source_path)\n",
    "\n",
    "\n",
    "    for i in range(len(file_names)) :\n",
    "        image = images[i]\n",
    "        H, W, C = image.shape\n",
    "        \n",
    "        image = cv2.resize(image, (W * 10, H * 10), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        file_path = os.path.join(export_path, file_names[i])\n",
    "        tiff.imwrite(file_path, image)\n",
    "\n",
    "def export_images_jpg(channels, source_path, export_path):\n",
    "    file_names = get_file_names(source_path)\n",
    "    \n",
    "    for i in range(len(file_names)):\n",
    "        # Stack the channels to form an RGB image\n",
    "        rgb_image = np.stack((channels[0][i], channels[1][i], channels[2][i]), axis=-1)\n",
    "\n",
    "        # Create an Image object\n",
    "        pil_image = Image.fromarray(rgb_image.astype(np.uint8), 'RGB')\n",
    "        # Define the file path\n",
    "        file_path = os.path.join(export_path, file_names[i].replace('tif', 'jpg'))\n",
    "        # Save the image as JPEG\n",
    "        pil_image.save(file_path, 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cae2245b-2fed-4deb-a0db-215cd8aee8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(tensor) :\n",
    "    tensor_array = tensor\n",
    "    \n",
    "    # Plot heatmap\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(tensor_array, cmap='viridis', annot=False, xticklabels=False, yticklabels=False, linewidths=0)\n",
    "    plt.title('Heatmap')\n",
    "    plt.xlabel('X-axis')\n",
    "    plt.ylabel('Y-axis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "304586a1-f315-4b79-b2c0-df7f79fd96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_labels(label_source_path, label_export_path) :\n",
    "    file_names = get_file_names(label_source_path)\n",
    "\n",
    "    for file_name in file_names :\n",
    "        file_path = os.path.join(label_source_path, file_name)\n",
    "        mask = tiff.imread(file_path)\n",
    "        H, W = mask.shape\n",
    "        \n",
    "        mask = cv2.resize(mask, (W * 10, H * 10), interpolation=cv2.INTER_LINEAR)\n",
    "        _, mask = cv2.threshold(mask, 0, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        H, W = mask.shape\n",
    "        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "        # convert the contours to polygons\n",
    "        polygons = []\n",
    "        for cnt in contours:\n",
    "            if cv2.contourArea(cnt) > 0:\n",
    "                polygon = []\n",
    "                for point in cnt:\n",
    "                    x, y = point[0]\n",
    "                    polygon.append(x / W)\n",
    "                    polygon.append(y / H)\n",
    "                polygons.append(polygon)\n",
    "    \n",
    "        # print the polygons\n",
    "        file_name = file_name.replace('mask', 's2_image')[:-4]+'.txt'\n",
    "        with open(os.path.join(label_export_path, file_name), 'w') as f:\n",
    "            for polygon in polygons:\n",
    "                for p_, p in enumerate(polygon):\n",
    "                    if p_ == len(polygon) - 1:\n",
    "                        f.write('{}\\n'.format(p))\n",
    "                    elif p_ == 0:\n",
    "                        f.write('0 {} '.format(p))\n",
    "                    else:\n",
    "                        f.write('{} '.format(p))\n",
    "    \n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c5bb8d5-a26c-4cd5-859f-47284645d185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_directory(data_name, overwrite=False) :\n",
    "    working_dir = os.getcwd()\n",
    "    container_dir = os.path.join(working_dir, 'preprocessed_data')\n",
    "    data_dir = os.path.join(container_dir, data_name)\n",
    "    images_dir = os.path.join(data_dir, 'images')\n",
    "    labels_dir = os.path.join(data_dir, 'labels')\n",
    "\n",
    "    os.makedirs(container_dir, exist_ok=True)\n",
    "\n",
    "    try :\n",
    "        os.makedirs(data_dir)\n",
    "        \n",
    "    except (FileExistsError) :\n",
    "        \n",
    "        if overwrite :\n",
    "            print('Data name exists, your data will be overwritten')\n",
    "\n",
    "        else :\n",
    "            print('Data name exists, quitting...')\n",
    "            return\n",
    "\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba03eada-9bac-4350-976e-7a8e9f5b9acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Path :  /datadisk2/c241_ml02/workspace/train_github/dataset/train/s2_image/\n",
      "Export Path :  /datadisk2/c241_ml02/workspace/train_github/preprocessed_data/20ch_minmax/images/\n",
      "Images Count :  2066\n",
      "Exporting...\n",
      "Done!!\n"
     ]
    }
   ],
   "source": [
    "image_path = 'dataset/train/s2_image/'\n",
    "label_path = 'dataset/train/mask/'\n",
    "\n",
    "image_source_path = os.path.join(os.getcwd(), image_path)\n",
    "image_export_path = os.path.join(os.getcwd(), f'preprocessed_data/{data_name}/images/')\n",
    "label_source_path = os.path.join(os.getcwd(), label_path)\n",
    "label_export_path = os.path.join(os.getcwd(), f'preprocessed_data/{data_name}/labels/')\n",
    "\n",
    "make_data_directory(data_name, overwrite=True)\n",
    "\n",
    "print('Source Path : ', image_source_path)\n",
    "print('Export Path : ', image_export_path)\n",
    "print('Images Count : ', len(get_file_names(image_source_path)))\n",
    "\n",
    "ch_num = [0,1,2,3,4,5,6,7,8,9,10,11]\n",
    "channels = []\n",
    "for i in ch_num :\n",
    "    ch = select_band(i, image_source_path)\n",
    "    channels.append(ch)\n",
    "\n",
    "for i in range(1, 4) :\n",
    "    for j in range(1, 4) :\n",
    "        if i != j :\n",
    "            ch = formula(channels[i], channels[j])\n",
    "            channels.append(ch)\n",
    "\n",
    "for i in range(10, 12) :\n",
    "    for j in range(10, 12) :\n",
    "        if i != j :\n",
    "            ch = formula(channels[i], channels[j])\n",
    "            channels.append(ch)\n",
    "    \n",
    "images = [np.stack([channels[i][j] for i in range(len(channels))], axis=-1, dtype=np.float32) for j in range(len(channels[0]))]\n",
    "preprocessed_images = []\n",
    "for image in images :\n",
    "    min_val, max_val = np.min(image), np.max(image)\n",
    "    image = (image - min_val) / (max_val - min_val) * 255\n",
    "    preprocessed_images.append(image)\n",
    "    \n",
    "print('Exporting...')\n",
    "\n",
    "\n",
    "export_images(preprocessed_images, image_source_path, image_export_path)\n",
    "export_labels(label_source_path, label_export_path)\n",
    "\n",
    "print('Done!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac126ef3-e164-4b6a-bfce-127a36af3eed",
   "metadata": {},
   "source": [
    "### Create 5 Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d416b86-8c14-42c3-979e-cb7874771802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fold(file_names, fold) :\n",
    "    random.shuffle(file_names)\n",
    "    \n",
    "    fold_sizes = [len(file_names) // fold for i in range(fold)]\n",
    "\n",
    "    for i in range(len(file_names) - sum(fold_sizes)) :\n",
    "        fold_sizes[-1] += 1\n",
    "\n",
    "    fold_data = []\n",
    "    for i in range(len(fold_sizes)) :\n",
    "        data = file_names[sum(fold_sizes[:i]): sum(fold_sizes[:i+1])]\n",
    "        fold_data.append(data)\n",
    "\n",
    "    return fold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c1e03de-6e25-418b-bf87-3825621b1af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_directory(data_name, fold) :\n",
    "    working_dir = os.getcwd()\n",
    "    container_path = os.path.join(working_dir, 'train_data')\n",
    "    data_path = os.path.join(container_path, data_name)\n",
    "    config_path = os.path.join(data_path, 'configs')\n",
    "\n",
    "    os.makedirs(container_path, exist_ok=True)\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    os.makedirs(config_path, exist_ok=True)\n",
    "    \n",
    "    for i in range(fold) :\n",
    "        fold_path = os.path.join(data_path, f'fold_{(i+1)}')\n",
    "        train_path = os.path.join(fold_path, 'train')\n",
    "        val_path = os.path.join(fold_path, 'val')\n",
    "        \n",
    "        os.makedirs(fold_path, exist_ok=True)\n",
    "        os.makedirs(train_path, exist_ok=True)\n",
    "        os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "        for path in [train_path, val_path] :  \n",
    "            images_dir = os.path.join(path, 'images')\n",
    "            labels_dir = os.path.join(path, 'labels')\n",
    "\n",
    "            os.makedirs(images_dir, exist_ok=True)\n",
    "            os.makedirs(labels_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3dda96b-736f-4e7b-95b0-dc00bb55f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data(data_name, source_path, destination_path, part) :\n",
    "\n",
    "    for file_name in data_name :\n",
    "        image_file_name = file_name + '.tif'\n",
    "        label_file_name = file_name + '.txt'\n",
    "\n",
    "        image_source_path = os.path.join(source_path, 'images', image_file_name)\n",
    "        image_destination_path = os.path.join(destination_path, part, 'images', image_file_name)\n",
    "\n",
    "        label_source_path = os.path.join(source_path, 'labels', label_file_name)\n",
    "        label_destination_path = os.path.join(destination_path, part, 'labels', label_file_name)\n",
    "\n",
    "        shutil.copy(image_source_path, image_destination_path)\n",
    "        shutil.copy(label_source_path, label_destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2327f64c-52b7-454f-a17c-2b5024cb6c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fold(data_name, fold_data, source_path, destination_path) :\n",
    "    \n",
    "    for i in range(len(fold_data)) :\n",
    "        train_data = []\n",
    "        fold_destination_path = os.path.join(destination_path, f'fold_{(i+1)}')\n",
    "        \n",
    "        for fold in fold_data :\n",
    "            if fold_data[i] == fold :\n",
    "                copy_data(fold_data[i], source_path, fold_destination_path, 'val')\n",
    "            else :\n",
    "                train_data += fold\n",
    "\n",
    "        copy_data(train_data, source_path, fold_destination_path, 'train')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebe513e1-69d1-4fea-a959-dca2c9dea8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_configs(data_name, fold, data_path, config_path) :    \n",
    "    for i in range(fold) :\n",
    "        fold_path = os.path.join(data_path, f'fold_{(i+1)}')\n",
    "        with open(os.path.join(config_path, f'fold_{(i+1)}.yaml'), 'w') as yaml :\n",
    "            config = f\"\"\"path: {fold_path}\n",
    "train: train\n",
    "val: val\n",
    "\n",
    "nc: 1\n",
    "names: ['solarpanel']\"\"\"\n",
    "\n",
    "            yaml.write(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3b20db0-5182-488b-a248-a42d83f11306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image_count(destination_path, fold) :\n",
    "    for i in range(fold) :\n",
    "        fold_path = os.path.join(destination_path, f'fold_{(i+1)}')\n",
    "        train_image_path = os.path.join(fold_path, 'train', 'images')\n",
    "        train_label_path = os.path.join(fold_path, 'train', 'labels')\n",
    "        val_image_path = os.path.join(fold_path, 'val', 'images')\n",
    "        val_label_path = os.path.join(fold_path, 'val', 'labels')\n",
    "        \n",
    "        print(f'=== Fold {(i+1)} ===')\n",
    "        print('Train Images:', len(os.listdir(train_image_path)))\n",
    "        print('Train Labels :', len(os.listdir(train_label_path)))\n",
    "        print('Val Images :', len(os.listdir(val_image_path)))\n",
    "        print('Val Labels :', len(os.listdir(val_label_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b79b433-5632-41f7-91c9-140846e60b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "source_path = os.path.join(working_dir, 'preprocessed_data', data_name)\n",
    "destination_path = os.path.join(working_dir, 'train_data', data_name)\n",
    "config_path = os.path.join(destination_path, 'configs')\n",
    "\n",
    "file_names = get_file_names(os.path.join(source_path, 'images'), remove_extension=True)\n",
    "make_train_directory(data_name, fold)\n",
    "\n",
    "fold_data = create_fold(file_names, fold)\n",
    "make_fold(data_name, fold_data, source_path, destination_path)\n",
    "write_configs(data_name, fold, destination_path, config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "815c5106-7b99-43f3-b50e-a278d797498d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Image Count per Fold ===\n",
      "\n",
      "=== Fold 1 ===\n",
      "Train Images: 1653\n",
      "Train Labels : 1653\n",
      "Val Images : 413\n",
      "Val Labels : 413\n",
      "=== Fold 2 ===\n",
      "Train Images: 1653\n",
      "Train Labels : 1653\n",
      "Val Images : 413\n",
      "Val Labels : 413\n",
      "=== Fold 3 ===\n",
      "Train Images: 1653\n",
      "Train Labels : 1653\n",
      "Val Images : 413\n",
      "Val Labels : 413\n",
      "=== Fold 4 ===\n",
      "Train Images: 1653\n",
      "Train Labels : 1653\n",
      "Val Images : 413\n",
      "Val Labels : 413\n",
      "=== Fold 5 ===\n",
      "Train Images: 1652\n",
      "Train Labels : 1652\n",
      "Val Images : 414\n",
      "Val Labels : 414\n"
     ]
    }
   ],
   "source": [
    "print('\\n=== Image Count per Fold ===\\n')\n",
    "check_image_count(destination_path, fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166bd01d-7d6a-47c1-9f33-7637f256ed0f",
   "metadata": {},
   "source": [
    "### Train YOLOv5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f033cf74-7595-4ad6-b060-4198b6332b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python yolov5/segment/train.py --img 256 --batch 128 --epochs 300 --data train_data/{data_name}/configs/fold_1.yaml --cfg yolov5/models/segment/{model} --device 5 --no-overlap --optimizer AdamW --patience 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092bb825-422f-4544-974e-99bca397b851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
