{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f72878-5d1b-4282-8deb-d6e2e4f7e740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m-seg summary: 220 layers, 21681734 parameters, 0 gradients, 75.8 GFLOPs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5120x160 and 38x12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 75\u001b[0m\n\u001b[1;32m     73\u001b[0m pred[:, :\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m=\u001b[39m scale_boxes(img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:], pred[:, :\u001b[38;5;241m4\u001b[39m], im0\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mround()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Extract masks\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m pred_masks \u001b[38;5;241m=\u001b[39m process_mask(proto, pred, pred[:, :\u001b[38;5;241m4\u001b[39m], (\u001b[38;5;241m640\u001b[39m, \u001b[38;5;241m640\u001b[39m))\n\u001b[1;32m     76\u001b[0m masks\u001b[38;5;241m.\u001b[39mappend(pred_masks)\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mprocess_mask\u001b[0;34m(proto, det, shape, upsample)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_mask\u001b[39m(proto, det, shape, upsample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Ensure det is correctly reshaped for matrix multiplication\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     masks \u001b[38;5;241m=\u001b[39m proto \u001b[38;5;241m@\u001b[39m det\u001b[38;5;241m.\u001b[39mT  \u001b[38;5;66;03m# Matrix multiplication\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     masks \u001b[38;5;241m=\u001b[39m masks\u001b[38;5;241m.\u001b[39msigmoid()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m upsample:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5120x160 and 38x12)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from utils.general import non_max_suppression, scale_boxes, check_img_size, Profile\n",
    "from utils.segment.general import process_mask, process_mask_native\n",
    "from utils.augmentations import letterbox\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.dataloaders import LoadImages\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "\n",
    "def process_mask(proto, det, shape, upsample=True):\n",
    "    # Ensure det is correctly reshaped for matrix multiplication\n",
    "    masks = proto @ det.T  # Matrix multiplication\n",
    "    masks = masks.sigmoid()\n",
    "    if upsample:\n",
    "        masks = torch.nn.functional.interpolate(masks.unsqueeze(0), size=shape, mode='bilinear', align_corners=False).squeeze(0)\n",
    "    return masks\n",
    "\n",
    "# Define variables\n",
    "model_path_tif = '/datadisk2/c241_ml02/workspace/yolov5/runs/train-seg/exp31/weights/best.pt'  # Path to the model\n",
    "model_path_rgb = '/datadisk2/c241_ml02/workspace/vanilla_yolo/yolov5/runs/train-seg/exp6/weights/best.pt'\n",
    "image_path_tif = '/datadisk2/c241_ml02/workspace/train_data/20ch_rescaled/fold_1/train/images/train_s2_image_0.tif'  # Path to the image\n",
    "image_path_rgb = '/datadisk2/c241_ml02/workspace/preprocessed_data/1_2_3_resized/images/train_s2_image_0.jpg'\n",
    "\n",
    "image_path = image_path_tif\n",
    "model_path = model_path_tif\n",
    "\n",
    "if image_path.endswith('.tif') :\n",
    "    height, width, channel = tiff.imread(image_path).shape\n",
    "elif image_path.endswith('.jpg') or image_path.endswith('jpeg') :\n",
    "    height, width, channel = cv2.imread(image_path).shape\n",
    "\n",
    "conf_thres = 0.25  # Confidence threshold\n",
    "iou_thres = 0.45  # IoU threshold for NMS\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
    "dt = Profile(device=device), Profile(device=device), Profile(device=device)\n",
    "\n",
    "# Load model\n",
    "imgsz=256\n",
    "model = DetectMultiBackend(model_path, device=device, dnn=False, fp16=False)\n",
    "stride, pt, jit, engine = model.stride, model.pt, model.jit, model.engine\n",
    "\n",
    "model.eval()\n",
    "model.warmup(imgsz=(1 if pt else batch_size, 20, imgsz, imgsz))\n",
    "\n",
    "# Load image\n",
    "dataset = LoadImages(image_path, img_size=640, stride=stride, auto=pt)\n",
    "for path, img, im0s, vid_cap, s in dataset:\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img = img.float()  # uint8 to fp16/32\n",
    "    # img /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "    if len(img.shape) == 3:\n",
    "        img = img[None]  # expand for batch dim\n",
    "\n",
    "    # Inference \n",
    "    with dt[1]:\n",
    "        preds, protos, train_out = model(img)\n",
    "\n",
    "    # NMS\n",
    "\n",
    "    with dt[2]:\n",
    "        preds = non_max_suppression(\n",
    "            preds, conf_thres, iou_thres, labels=None, multi_label=False, agnostic=True, max_det=150, nm=32\n",
    "        ) \n",
    "\n",
    "    # Process predictions\n",
    "    masks = []  # Array to hold mask arrays\n",
    "    im0 = im0s.copy()\n",
    "    for si, (pred, proto) in enumerate(zip(preds, protos)):\n",
    "        if len(pred):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            pred[:, :4] = scale_boxes(img.shape[2:], pred[:, :4], im0.shape).round()\n",
    "            # Extract masks\n",
    "            pred_masks = process_mask(proto, pred, pred[:, :4], (640, 640))\n",
    "            masks.append(pred_masks)\n",
    "\n",
    "# 'masks' now contains the mask arrays for the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5dfccd5-cda5-42cc-b0f3-f73569e6c780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1msegment/val: \u001b[0mdata=/datadisk2/c241_ml02/workspace/train_data/20ch_rescaled/configs/fold_1.yaml, weights=['/datadisk2/c241_ml02/workspace/yolov5/runs/train-seg/exp33/weights/best.pt'], batch_size=32, imgsz=640, conf_thres=0.45, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val-seg, name=exp, exist_ok=False, half=False, dnn=False\n",
      "WARNING ‚ö†Ô∏è confidence threshold 0.45 > 0.001 produces invalid results\n",
      "YOLOv5 üöÄ v7.0-313-g712de55a Python-3.12.3 torch-2.3.0.post300 CUDA:0 (NVIDIA H100 80GB HBM3, 81004MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m-seg summary: 220 layers, 21681734 parameters, 0 gradients, 75.8 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /datadisk2/c241_ml02/workspace/train_data/20ch_rescaled/fold_1/val\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mWARNING ‚ö†Ô∏è NMS time limit 2.100s exceeded\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        413       1088      0.169     0.0846      0.105     0.0373      0.138     0.0689     0.0861     0.0261\n",
      "Speed: 33.9ms pre-process, 4.6ms inference, 7.4ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/val-seg/exp18\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "validation_path = '/datadisk2/c241_ml02/workspace/yolov5/segment/val.py'\n",
    "model_path = '/datadisk2/c241_ml02/workspace/yolov5/runs/train-seg/exp33/weights/best.pt'\n",
    "\n",
    "data_path = '/datadisk2/c241_ml02/workspace/train_data/20ch_rescaled/configs/fold_1.yaml'\n",
    "\n",
    "!python {validation_path} --weights {model_path} --data {data_path} --conf-thres 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40b419-87b5-40fe-afcb-9a21594d719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proto)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
